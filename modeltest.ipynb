{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(' a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Training dataset...\n",
      "Loading labels: train_interaction.npy\n",
      "Loading chemIDs: train_chemIDs.npy\n",
      "Loading proIDs: train_proIDs.txt\n",
      "Loading sequences: train_reprotein.npy\n",
      "interactions.shape:  (14196, 1) ecfp.shape:  (14196, 1024) sequences.shape:  (14196, 1, 5762, 20) n2vc.shape: (14196, 128) n2vp.shape: (14196, 128)\n"
     ]
    }
   ],
   "source": [
    "#  making feature vectors of seq, one-hot encoding\n",
    "\n",
    "print('Making Training dataset...')\n",
    "ecfp = np.load('./dataset_hard'+'/cv_'+str(0)+'/train_fingerprint.npy')\n",
    "ecfp = np.asarray(ecfp, dtype='float32').reshape(-1,1024)\n",
    "\n",
    "file_interactions=np.load('./dataset_hard'+'/cv_'+str(0)+'/train_interaction.npy')\n",
    "print('Loading labels: train_interaction.npy')\n",
    "cID = np.load('./dataset_hard'+'/cv_'+str(0)+'/train_chemIDs.npy')\n",
    "print('Loading chemIDs: train_chemIDs.npy')\n",
    "with open('./dataset_hard'+'/cv_'+str(0)+'/train_proIDs.txt') as f:\n",
    "    pID = [s.strip() for s in f.readlines()]\n",
    "print('Loading proIDs: train_proIDs.txt')\n",
    "n2v_c, n2v_p = [], []\n",
    "with open('./modelpp.pickle', mode='rb') as f:\n",
    "    modelpp = pickle.load(f)\n",
    "with open('./modelcc.pickle', mode='rb') as f:\n",
    "    modelcc = pickle.load(f)\n",
    "for j in cID:\n",
    "    n2v_c.append(modelcc.wv[str(j)])\n",
    "for k in pID:\n",
    "    n2v_p.append(modelpp.wv[k])\n",
    "interactions = np.asarray(file_interactions, dtype='int32').reshape(-1,1)\n",
    "n2vc = np.asarray(n2v_c, dtype='float32').reshape(-1, 128)\n",
    "n2vp = np.asarray(n2v_p, dtype='float32').reshape(-1, 128)\n",
    "#reset memory\n",
    "del n2v_c, n2v_p, cID, pID, modelcc, modelpp, file_interactions\n",
    "gc.collect()\n",
    "\n",
    "file_sequences=np.load('./dataset_hard'+'/cv_'+str(0)+'/train_reprotein.npy')\n",
    "print('Loading sequences: train_reprotein.npy', flush=True)\n",
    "sequences = np.asarray(file_sequences, dtype='float32').reshape((-1, 1, 5762, 20))\n",
    "# reset memory\n",
    "del file_sequences\n",
    "gc.collect()\n",
    "\n",
    "print('interactions.shape: ', interactions.shape, 'ecfp.shape: ', ecfp.shape,'sequences.shape: ',  sequences.shape, 'n2vc.shape:', n2vc.shape,'n2vp.shape:', n2vp.shape, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('use', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepCNN(\n",
       "  (conv1_pro): Conv2d(1, 64, kernel_size=(33, 20), stride=(1,), padding=(16, 0))\n",
       "  (bn1_pro): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_pro): Conv2d(64, 64, kernel_size=(23, 1), stride=(1,), padding=(11, 0))\n",
       "  (bn2_pro): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_pro): Conv2d(64, 32, kernel_size=(33, 1), stride=(1,), padding=(16, 0))\n",
       "  (bn3_pro): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3_pro): Linear(in_features=1, out_features=70, bias=True)\n",
       "  (fc4): Linear(in_features=1152, out_features=80, bias=True)\n",
       "  (fc5): Linear(in_features=80, out_features=60, bias=True)\n",
       "  (fc4_pro): Linear(in_features=2368, out_features=80, bias=True)\n",
       "  (fc5_pro): Linear(in_features=80, out_features=60, bias=True)\n",
       "  (fc6): Linear(in_features=3600, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "# prosize: 5762, plensize:20\n",
    "# j1:33, s1:1, pf1:64 = window-size, stride-step, No. of filters of first protein-CNN convolution layer\n",
    "# ja1:17 sa1:1 = window-size, stride-step of first protein-CNN average-pooling layer\n",
    "# j2:23,s2:1, pf2:64 = second protein-CNN convolution layer\n",
    "# ja2:11, sa2:1 = second protein-CNN average-pooling layer\n",
    "# j3:33, s3:1, pf3:32 = third protein-CNN convolution layer\n",
    "# ja3:17, sa3:1 third protein-CNN average-pooling layer\n",
    "# n_hid3:70, n_hid4:80, n_hid5:60, n_out:1\n",
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        # first conv of seq_cnn\n",
    "        self.conv1_pro = nn.Conv2d(1, 64, (33, 20), stride= (1, ), padding=(33//2, 0))\n",
    "        self.bn1_pro = nn.BatchNorm2d(64)\n",
    "        # second conv of seq_cnn\n",
    "        self.conv2_pro = nn.Conv2d(64, 64, (23, 1), stride= (1, ), padding=(23//2, 0))\n",
    "        self.bn2_pro = nn.BatchNorm2d(64)\n",
    "        # third conv of seq_cnn\n",
    "        self.conv3_pro = nn.Conv2d(64, 32, (33, 1), stride=(1, ), padding=(33//2, 0))\n",
    "        self.bn3_pro = nn.BatchNorm2d(32)\n",
    "        self.fc3_pro = nn.Linear(1, 70)\n",
    "        self.fc4 = nn.Linear(1152, 80) # 1024 + 128\n",
    "        self.fc5 = nn.Linear(80, 60) # nhid4, nhid5\n",
    "        self.fc4_pro = nn.Linear(2368, 80) # 2240+128\n",
    "        self.fc5_pro = nn.Linear(80, 60)\n",
    "        self.fc6 = nn.Linear(3600, 1)  #\n",
    "\n",
    "\n",
    "        self.m1 = (5762+(33//2*2)-33)//1+1\n",
    "        # print('m1', self.m1)\n",
    "        self.m2 = (self.m1+(17//2*2)-17)//1+1\n",
    "        # print('m2', self.m2)\n",
    "        self.m3 = (self.m2+(23//2*2)-23)//1+1\n",
    "        # print('m3', self.m3)\n",
    "        self.m4 = (self.m3+(11//2*2)-11)//1+1\n",
    "        # print('m4', self.m4)\n",
    "        self.m5 = (self.m4+(33//2*2)-33)//1+1\n",
    "        # print('m5', self.m5)\n",
    "        self.m6 = (self.m5+(17//2*2)-17)//1+1\n",
    "        # print('m6', self.m6)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq = self.conv1_pro(seq)  # first conv\n",
    "        seq = self.bn1_pro(seq)    # batch norm\n",
    "        seq = F.leaky_relu(seq)    # leaky_relu activation\n",
    "        seq = F.dropout(seq, p=0.2) # dropout\n",
    "        seq = F.avg_pool2d(seq, (17, 1), stride=1, padding=(17//2, 0)) # avg_pooling\n",
    "\n",
    "        seq = self.conv2_pro(seq)\n",
    "        seq = self.bn2_pro(seq)\n",
    "        seq = F.leaky_relu(seq)\n",
    "        seq = F.dropout(seq, p=0.2)\n",
    "        seq = F.avg_pool2d(seq, (11, 1), stride=1, padding=(11//2, 0))\n",
    "\n",
    "        seq = self.conv3_pro(seq)\n",
    "        seq = self.bn3_pro(seq)\n",
    "        seq = F.leaky_relu(seq)\n",
    "        seq = F.dropout(seq, p=0.2)\n",
    "        seq = F.avg_pool2d(seq, (17, 1), stride=1, padding=(17//2, 0))\n",
    "        seq_protein = F.max_pool2d(seq, (self.m6, 1))\n",
    "        # fully-connect fc3\n",
    "        seq_protein = F.leaky_relu(self.fc3_pro(seq_protein))\n",
    "        seq_protein = F.dropout(seq_protein, p=0.2)\n",
    "        return seq_protein\n",
    "\n",
    "    def cos_similarity(self, fp, seq_, n2c, n2p):\n",
    "        x_compound = fp\n",
    "        x_compound = self.fc4(torch.concat((x_compound, n2c)))\n",
    "        x_compound = F.dropout(F.leaky_relu(x_compound), p=0.2)\n",
    "        x_compound = F.dropout(F.leaky_relu(self.fc5(x_compound)), p=0.2)\n",
    "        x_protein = self.predict_pro(seq_)\n",
    "        x_protein = self.fc4_pro(torch.cat((x_protein, n2p)))\n",
    "        x_protein = F.dropout(F.leaky_relu(x_protein), p=0.2)\n",
    "        #print(x_protein.shape)\n",
    "        x_protein = F.dropout(F.leaky_relu(self.fc5_pro(x_protein)), p=0.2)\n",
    "        #print(x_protein.shape)\n",
    "        y = x_compound * x_protein\n",
    "        return y\n",
    "\n",
    "    def __call__(self, fp, seq_, n2c, n2p, interaction):\n",
    "        z = self.cos_similarity(ecfp, sequences, n2vc, n2vp)\n",
    "        print('Z shape:', z.shape)\n",
    "        Z = self.fc6(z)\n",
    "\n",
    "        loss = F.cosine_similarity(Z, interactions)\n",
    "        # loss = tf.compat.v1.losses.sigmoid_cross_entropy(Z, interactions)\n",
    "        # ---------------------------------------------------------------\n",
    "        accuracy = Accuracy(Z, interactions)\n",
    "        # accuracy_ = tf.keras.metrics.binary_accuracy(Z, interactions) #---\n",
    "        # ---------------------------------------------------------------\n",
    "        print({'loss': loss, 'accuracy': accuracy}, self)\n",
    "        return loss\n",
    "\n",
    "\n",
    "model = DeepCNN()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSTART = time.time()\\nfeatures = []\\nfor i in range(14196):\\n    seq_pro = torch.from_numpy(sequences[i].astype(np.float32)).clone()\\n    seq_pro = seq_pro.reshape(1, 1, 5762, 20)\\n    #print(seq.shape)\\n    seq = seq_pro.to(device)\\n    with torch.no_grad():\\n        feature = model(seq)\\n    features.append(feature.cpu().detach().numpy().reshape(-1))\\nfeatures = np.array(features)\\nprint(features.shape)\\n\\nEND = time.time()\\nprint('Total time is {} sec．'.format(END-START))\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "START = time.time()\n",
    "features = []\n",
    "for i in range(14196):\n",
    "    seq_pro = torch.from_numpy(sequences[i].astype(np.float32)).clone()\n",
    "    seq_pro = seq_pro.reshape(1, 1, 5762, 20)\n",
    "    #print(seq.shape)\n",
    "    seq = seq_pro.to(device)\n",
    "    with torch.no_grad():\n",
    "        feature = model(seq)\n",
    "    features.append(feature.cpu().detach().numpy().reshape(-1))\n",
    "features = np.array(features)\n",
    "print(features.shape)\n",
    "\n",
    "END = time.time()\n",
    "print('Total time is {} sec．'.format(END-START))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  11356\n",
      "valid:  2840\n"
     ]
    }
   ],
   "source": [
    "#import chainer.functions as F\n",
    "#from chainer import datasets\n",
    "# print(ecfp.shape, n2vc.shape)\n",
    "\n",
    "# train_dataset = datasets.TupleDataset(ecfp, sequences, n2vc, n2vp, interactions)\n",
    "# train_dataset in chainer:\n",
    "# (ecfp, sequences, n2vc, n2vp, interactions)\n",
    "# ...\n",
    "# (ecfp, sequences, n2vc, n2vp, interactions)  14196 x 5\n",
    "dataset_pytorch = []\n",
    "\n",
    "for i in range(14196):\n",
    "    dataset_pytorch.append((torch.from_numpy(ecfp[i, :].astype(np.float32)).clone(),\n",
    "                            torch.from_numpy(sequences[i].astype(np.float32)).clone(),\n",
    "                            torch.from_numpy(n2vc[i, :].astype(np.float32)).clone(),\n",
    "                            torch.from_numpy(n2vp[i, :].astype(np.float32)).clone(),\n",
    "                            torch.from_numpy(interactions[i].astype(np.float32)).clone()))\n",
    "\n",
    "# print(len(dataset_pytorch), len(dataset_pytorch[0]))\n",
    "\n",
    "n = int(0.8 * len(dataset_pytorch))\n",
    "train_dataset_pytorch, valid_dataset_pytorch = dataset_pytorch[:n], dataset_pytorch[n:]\n",
    "print('train: ', len(train_dataset_pytorch), flush=True)\n",
    "print('valid: ', len(valid_dataset_pytorch), flush=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_pytorch, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(valid_dataset_pytorch, batch_size=100, shuffle=True)\n",
    "#ecfp_ = torch.from_numpy(ecfp.astype(np.float32)).clone()\n",
    "#n2vc_ = torch.from_numpy(n2vc.astype(np.float32)).clone()\n",
    "#a = torch.concat(ecfp_.to(device), n2vc_.to(device))\n",
    "# a = F.concat(ecfp, n2vc)\n",
    "\n",
    "# print(a.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is setting up...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\handlers\\checkpoint.py:851: UserWarning: Argument save_interval is deprecated and should be None. This argument will be removed in 0.5.0.Please, use events filtering instead, e.g. Events.ITERATION_STARTED(every=1000)\n",
      "  warnings.warn(msg)\n",
      "Current run is terminating due to exception: too many values to unpack (expected 2)\n",
      "Engine run is terminating due to exception: too many values to unpack (expected 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9171b03c19f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_event_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LOSS:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    751\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m                 \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m                 \u001b[1;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Current run is terminating due to exception: {e}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(engine, batch)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asse9\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ignite\\engine\\__init__.py\u001b[0m in \u001b[0;36m_prepare_batch\u001b[1;34m(batch, device, non_blocking)\u001b[0m\n\u001b[0;32m     35\u001b[0m ) -> Tuple[Union[torch.Tensor, Sequence, Mapping, str, bytes], ...]:\n\u001b[0;32m     36\u001b[0m     \u001b[1;34m\"\"\"Prepare batch for training: pass to a device with options.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     return (\n\u001b[0;32m     39\u001b[0m         \u001b[0mconvert_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.engine import create_supervised_trainer, create_supervised_evaluator, Events\n",
    "\n",
    "# train initialize\n",
    "\n",
    "output_dir ='./result/dataset_hard'+'/'+'ecfpN2vc_mSGD'+'/'+'pattern'+str(0)\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "#-------------------------------\n",
    "#reset memory again\n",
    "del sequences, interactions, ecfp, n2vc, n2vp\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "print('Trainer is setting up...', flush=True)\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n",
    "evaluator = create_supervised_evaluator(model, metrics={'accuracy': Accuracy(), 'nll': Loss(F.nll_loss)}, device=device)\n",
    "training_history = {'accuracy': [], 'loss': []}\n",
    "validation_history = {'accuracy': [], 'loss': []}\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_nll = metrics['nll']\n",
    "    training_history['accuracy'].append(avg_accuracy)\n",
    "    training_history['loss'].append(avg_nll)\n",
    "    print(\n",
    "        \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll)\n",
    "    )\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(test_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_nll = metrics['nll']\n",
    "    validation_history['accuracy'].append(avg_accuracy)\n",
    "    validation_history['loss'].append(avg_nll)\n",
    "    print(\n",
    "        \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    './models',\n",
    "    'model',\n",
    "    save_interval=1,\n",
    "    n_saved=2,\n",
    "    create_dir=True,\n",
    "    save_as_state_dict=True,\n",
    "    require_empty=False,\n",
    ")\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'Model': model})\n",
    "trainer.run(train_loader, max_epochs=150)\n",
    "print('LOSS:', model(train_loader))\n",
    "\n",
    "print(' over ')\n",
    "#print('Nice, your Learning Job is done.　Total time is {} sec．'.format(END-START))\n",
    "\n",
    "del model, trainer\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
